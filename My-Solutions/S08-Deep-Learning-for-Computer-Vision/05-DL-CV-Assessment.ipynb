{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning for Image Classification Assessment\n",
    "\n",
    "\n",
    "Welcome to your assessment! Follow the instructions in bold below to complete the assessment.\n",
    "\n",
    "If you get stuck, check out the solutions video and notebook. (Make sure to run the solutions notebook before posting a question to the QA forum please, thanks!)\n",
    "\n",
    "------------\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "**Your task is to build an image classifier with Keras and Convolutional Neural Networks for the Fashion MNIST dataset. This data set includes 10 labels of different clothing types with 28 by 28 *grayscale* images. There is a training set of 60,000 images and 10,000 test images.**\n",
    "\n",
    "    Label\tDescription\n",
    "    0\t    T-shirt/top\n",
    "    1\t    Trouser\n",
    "    2\t    Pullover\n",
    "    3\t    Dress\n",
    "    4\t    Coat\n",
    "    5\t    Sandal\n",
    "    6\t    Shirt\n",
    "    7\t    Sneaker\n",
    "    8\t    Bag\n",
    "    9\t    Ankle boot\n",
    "    \n",
    " "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "**TASK 1: Run the code below to download the dataset using Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the Data\n",
    "\n",
    "**TASK 2: Use matplotlib to view an image from the data set. It can be any image from the data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   1,   0,   0,   0,   0,  41, 188, 103,\n",
       "         54,  48,  43,  87, 168, 133,  16,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   0,  49, 136, 219, 216, 228, 236,\n",
       "        255, 255, 255, 255, 217, 215, 254, 231, 160,  45,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  14, 176, 222, 224, 212, 203, 198, 196,\n",
       "        200, 215, 204, 202, 201, 201, 201, 209, 218, 224, 164,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0, 188, 219, 200, 198, 202, 198, 199, 199,\n",
       "        201, 196, 198, 198, 200, 200, 200, 200, 201, 200, 225,  41,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  51, 219, 199, 203, 203, 212, 238, 248, 250,\n",
       "        245, 249, 246, 247, 252, 248, 235, 207, 203, 203, 222, 140,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 116, 226, 206, 204, 207, 204, 101,  75,  47,\n",
       "         73,  48,  50,  45,  51,  63, 113, 222, 202, 206, 220, 224,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 200, 222, 209, 203, 215, 200,   0,  70,  98,\n",
       "          0, 103,  59,  68,  71,  49,   0, 219, 206, 214, 210, 250,  38,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 247, 218, 212, 210, 215, 214,   0, 254, 243,\n",
       "        139, 255, 174, 251, 255, 205,   0, 215, 217, 214, 208, 220,  95,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,  45, 226, 214, 214, 215, 224, 205,   0,  42,  35,\n",
       "         60,  16,  17,  12,  13,  70,   0, 189, 216, 212, 206, 212, 156,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 164, 235, 214, 211, 220, 216, 201,  52,  71,  89,\n",
       "         94,  83,  78,  70,  76,  92,  87, 206, 207, 222, 213, 219, 208,\n",
       "          0,   0],\n",
       "       [  0,   0,   0, 106, 187, 223, 237, 248, 211, 198, 252, 250, 248,\n",
       "        245, 248, 252, 253, 250, 252, 239, 201, 212, 225, 215, 193, 113,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,  17,  54, 159, 222, 193, 208, 192, 197,\n",
       "        200, 200, 200, 200, 201, 203, 195, 210, 165,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  47, 225, 192, 214, 203, 206,\n",
       "        204, 204, 205, 206, 204, 212, 197, 218, 107,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   1,   6,   0,  46, 212, 195, 212, 202, 206,\n",
       "        205, 204, 205, 206, 204, 212, 200, 218,  91,   0,   3,   1,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,  11, 197, 199, 205, 202, 205,\n",
       "        206, 204, 205, 207, 204, 205, 205, 218,  77,   0,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   3,   0,   2, 191, 198, 201, 205, 206,\n",
       "        205, 205, 206, 209, 206, 199, 209, 219,  74,   0,   5,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   2,   0,   0, 188, 197, 200, 207, 207,\n",
       "        204, 207, 207, 210, 208, 198, 207, 221,  72,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   2,   0,   0, 215, 198, 203, 206, 208,\n",
       "        205, 207, 207, 210, 208, 200, 202, 222,  75,   0,   4,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 212, 198, 209, 206, 209,\n",
       "        206, 208, 207, 211, 206, 205, 198, 221,  80,   0,   3,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 204, 201, 205, 208, 207,\n",
       "        205, 211, 205, 210, 210, 209, 195, 221,  96,   0,   3,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 202, 201, 205, 209, 207,\n",
       "        205, 213, 206, 210, 209, 210, 194, 217, 105,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 204, 204, 205, 208, 207,\n",
       "        205, 215, 207, 210, 208, 211, 193, 213, 115,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 204, 207, 207, 208, 206,\n",
       "        206, 215, 210, 210, 207, 212, 195, 210, 118,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 198, 208, 208, 208, 204,\n",
       "        207, 212, 212, 210, 207, 211, 196, 207, 121,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 198, 210, 207, 208, 206,\n",
       "        209, 213, 212, 211, 207, 210, 197, 207, 124,   0,   1,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 172, 210, 203, 201, 199,\n",
       "        204, 207, 205, 204, 201, 205, 197, 206, 127,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 188, 221, 214, 234, 236,\n",
       "        238, 244, 244, 244, 240, 243, 214, 224, 162,   0,   2,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   1,   0,   0, 139, 146, 130, 135, 135,\n",
       "        137, 125, 124, 125, 121, 119, 114, 130,  76,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d81a2f32e8>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAE3VJREFUeJzt3WuMXOV5B/D/M7Ozu17f7cUXzMY2jikXBwzZOBe3iQmFAiIyKA1gVZEjpZiiIDUVqkr9oXYbVaJRgfAhIXKKGyOBQ6RADRUpQVaLCW1s1g7CJg6BGCf4wq6NjXftvc3l6YedRRuz53nHc2bOmfXz/0lod+fZM/Mynv+enX3O+76iqiAifzJpD4CI0sHwEznF8BM5xfATOcXwEznF8BM5xfATOcXwEznF8BM51ZTkgzVLi7ZicpIPeX6YPMksN3UMR9YGPmi1j+23r/CUUuAK0EC50BZ9fpHpBfvYYfvl2XpkyKxrwb7/89EgzmBYh6SS740VfhG5EcAjALIA/k1VH7C+vxWT8Wm5Ls5D1o8Enq80L4Ne9gmzPPPhw5G1fc9dah47Z0/0Dw4AyA4VzboMl8z68avaou/7lvfNY98/ONOsX/qtd8x6sbvHrJ+Pdur2ir+36l/7RSQL4LsAbgJwOYA1InJ5tfdHRMmK855/BYC3VfWAqg4D+BGA1bUZFhHVW5zwLwDw7pivD5Vv+wMisk5EukSkKw/7PRoRJSdO+Md7k/yRN8aquklVO1W1M4eWGA9HRLUUJ/yHAHSM+foiAEfiDYeIkhIn/K8CWCoii0WkGcCdAJ6tzbCIqN6qbvWpakFE7gXwAkZafZtV9Y2ajexcxW3VxWjlFVddY9Z/e4f9NP/jtU+b9UG1W1aLcscia3Pu/ql57PKW9N6KPXZqnlnPX5w163fd9q5Zf2Uo+tx2zy//wjx2wUM5sy6vvGbWJ4JYfX5VfR7A8zUaCxEliJf3EjnF8BM5xfATOcXwEznF8BM5xfATOSVJ7tgzTWZpo07pzbbPNusDW6dE1u5Z+D/msc1iT4s9ONxu1nuGp5n108XoXn1B7V75pIw9pXfppG6zfmh4llnPG49f0oqmnVetPXc6sjY3d8o8dka236xveONLZn3erfvNer3s1O3o1RMVPbE88xM5xfATOcXwEznF8BM5xfATOcXwEzmV6NLdjWzaNrvleefsVyJrO/uWmMda7S4AmJTNm/WBoj29NCPRY28We/lq61gAeP1Mh1lvCrQxLbkYx1aiZ3hqZO14Prp1C4TbkN+6YptZ/+6KL5t17Npr1xPAMz+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RU276/IUvftKs3zzb7tvuObMostYWmBbbArvXPqe516xfP9meHnphNrpXnxP753tfyR5bW8a+RmFI7V16rUefmmk2j+0v2dc/HCjYL9+f9l0Zfd9F+7HH3Y9qjEG1r734zV/aW6Nfssu+/yTwzE/kFMNP5BTDT+QUw0/kFMNP5BTDT+QUw0/kVKw+v4gcBNAHoAigoKqdtRhUPRz6ot3Xnd0UvcwzAMxsil7KOTRfvzVj96uP56PnnQPAnd+7z6xPPhLda5/6uyHz2NMd9hbdUw7bx2vGbohnhqPHVmyxn7f8NLvec7X98v2nNU9E1nafWWweG7p2I6/2Yz987Vaz/ig+btaTUIuLfK5V1eM1uB8iShB/7SdyKm74FcDPRGS3iKyrxYCIKBlxf+1fqapHRGQOgBdF5NequmPsN5R/KKwDgFa0xXw4IqqVWGd+VT1S/tgD4BkAK8b5nk2q2qmqnTnYf1wiouRUHX4RmSwiU0c/B3ADgH21GhgR1VecX/vnAnhGREbv50lV/a+ajIqI6q7q8KvqAQBX1XAsdXXLTTvN+pmS/ZbE6tUPBeaVtzf1mfW3Buaa9Qu//b9mve+Oz0TWuldMMo+d/6B934fv/5xZb99rX8OQb4+e965Z+xqBtvfsXvvCDfak+ME7oh871Mdvz9n/ZkfyM8z6PTPeMOvf/+TqyJruto+tFbb6iJxi+ImcYviJnGL4iZxi+ImcYviJnHKzdPffz3nZrP9nYIpni9Hqm5mzl68OuXjSMbO+D7PN+ssPfS+ydrgYPRUZAL5wyd+Y9Xe+FH3fAPD5vbeZ9ReveCqy1hZYunvDsSvM+i+uspfP7jfatxc1nzCPDS3NnS/Z0dl2ZoFZP/on0yNr83abh9YMz/xETjH8RE4x/EROMfxETjH8RE4x/EROMfxETp03fX5dudys7xz6tVkPTenNSTGy1ir2tNZ5uVNm/Zf9C816yM1f/lpkLTNgj+1jHfa02pv/4QazPlXs6wj+fOjPoouBZb8/+NNL7MfGL8z6jpPRx6+a9aZ5bGg59lD9WMFejn3ws8ZS8d8xD60ZnvmJnGL4iZxi+ImcYviJnGL4iZxi+ImcYviJnDpv+vzdf2tvJT0v22vWD+ICsz5Uip7fPTfQx+8pTDPr/UV7XnvhumvM+sAF0WMbmGX/fDf+twAAZ+YtMeuB3cfRNKiRtWKz3ecfmmHXB//qs2b9c1Neiqz15O1/k0taj5r1LKL/vwBgevaMWV97WfRS8i/BXm69VnjmJ3KK4SdyiuEncorhJ3KK4SdyiuEncorhJ3Iq2OcXkc0AbgHQo6rLyrfNAvAUgEUADgK4XVVP1m+YYYVdM836v7TfZNbvmPOqWV/a3BNZ68ja6/b/+6llZn0osAb8849/36znNXqtgbzaYxsM1FvFPj+0ZewLBTLG+WVI7YsEcmLPmT+Qt4/ffGJlZG1Bi/1yDa3RkJOCWX/pg0vN+isvXBlZWwh72/RaqeTM/0MAN5512/0AtqvqUgDby18T0QQSDL+q7gBw9vYmqwFsKX++BcCtNR4XEdVZte/556rqUQAof5xTuyERURLqfm2/iKwDsA4AWtFW74cjogpVe+bvFpH5AFD+GPnXMFXdpKqdqtqZg71IJhElp9rwPwtgbfnztQC21WY4RJSUYPhFZCuA/wPwRyJySES+DuABANeLyFsAri9/TUQTiKja85JraZrM0k/LdYk93rlomjfXrA9c2RFZe2/doHnsxiufM+svnPiEWV/Sdsysv9Uf/ffWydlh89iW0IT8OsqI/dqz9koAgPfzk836x9uir8148refMo+ds9re56FR7dTt6NUT9kIIZbzCj8gphp/IKYafyCmGn8gphp/IKYafyKnzZunuuArvdZv1nFFfMHC1eWzrZrudVoLdmZneZG+DPb8leunwlow99TS01XRIVuwpwRljievQY7fn+sx6b8Fe4vqCpujjh3bNMo/1gGd+IqcYfiKnGH4ipxh+IqcYfiKnGH4ipxh+Iqf89PnF7qVnWuxVhkqDxrTdwLToA8P2EofNMXvxxRg/w0N9+qI27vkhznRk49KIikiTHR0t2tORQ6+ZJDTuvywR1RXDT+QUw0/kFMNP5BTDT+QUw0/kFMNP5JSfPn+gr1oaGqr6rnP73jHrb/fby4JPytr96pMFe4lqS2itAGu+PQAEutVB1nUEoesXQv/fU5qq/zdr7o3ZZ88G1kEo2NduNAKe+YmcYviJnGL4iZxi+ImcYviJnGL4iZxi+ImcCvb5RWQzgFsA9KjqsvJtGwHcBWB07+j1qvp8vQaZBAn0bdXo2xZ7T5vH9gb61TNyA2a9v9hs1tuMbbhDffzQdQBx1uUH7G22i2Kfe04W2sz6/GZ7Un4G0WOXYvrz6dNWyZn/hwBuHOf2h1V1efm/CR18Io+C4VfVHQBOJDAWIkpQnPf894rI6yKyWURm1mxERJSIasP/KIAlAJYDOArgwahvFJF1ItIlIl15VH8tNhHVVlXhV9VuVS2qagnADwCsML53k6p2qmpnDvYimUSUnKrCLyLzx3x5G4B9tRkOESWlklbfVgCrALSLyCEAGwCsEpHlABTAQQB313GMRFQHwfCr6ppxbn6sDmNJlZZi9H1L9qz34ZL9NJcCa+OX1O7FW730kHwpZ9ZbY6yNDwAZ4zqB0LhD/9+h9QCajfsPXL4QFuf10iB4hR+RUww/kVMMP5FTDD+RUww/kVMMP5FTfpbuTtGqmW+a9V/1X2jWWwJbeFvbaIfaaaEpu2kKjb2v2GrWrTZjoEvoAs/8RE4x/EROMfxETjH8RE4x/EROMfxETjH8RE6xzz9K69fvHlR72mzI9CZ7ae9BY1pucOntwNblsZf+No7vDzTbQ1twn8zbS3tbU6WLOXvcQXV8vSSFZ34ipxh+IqcYfiKnGH4ipxh+IqcYfiKnGH4ip9jnT8Dx/FSzHpqv31+yt+hukejjQ8tbh/r0oaW7TxUnmfWicf9tWbuPH1rS/L3SNLNuGZ4Rs89/HuCZn8gphp/IKYafyCmGn8gphp/IKYafyCmGn8ipYJ9fRDoAPA5gHoASgE2q+oiIzALwFIBFAA4CuF1VT9ZvqBNXqNcelzVnvxTzsUNr54fm+1tCfXxr3f1Kjj9TaomsFewl/4NibeneICo58xcA3KeqlwH4DIBviMjlAO4HsF1VlwLYXv6aiCaIYPhV9aiq7il/3gdgP4AFAFYD2FL+ti0Abq3XIImo9s7pPb+ILAJwNYCdAOaq6lFg5AcEgDm1HhwR1U/F4ReRKQB+AuCbqtp7DsetE5EuEenKw76Wm4iSU1H4RSSHkeA/oapPl2/uFpH55fp8AD3jHauqm1S1U1U7c4j+AwwRJSsYfhERAI8B2K+qD40pPQtgbfnztQC21X54RFQvlUzpXQngqwD2ishr5dvWA3gAwI9F5OsAfg/gK/UZ4sQXapcFZtUGWVt0x5UzpgsD8bb4Do079LyV1H7i+q1WX9vEb9XFFQy/qv4c0S/P62o7HCJKCq/wI3KK4SdyiuEncorhJ3KK4SdyiuEncopLd48KbFVdT6HlseMI9dLjTMkFgJYYYw8tGx6a0tuUsa8DGNTol3edZ1lPCDzzEznF8BM5xfATOcXwEznF8BM5xfATOcXwEznFPv8oCUyqj3EdQG9gnei25uGq7zsktGx46BqDQc2Z9dCc+zjLloeW5s6K/W8yVIoee+wlELT6dQwaBc/8RE4x/EROMfxETjH8RE4x/EROMfxETjH8RE6xz98Achl7bXyrXw3Yc/JDffhQPRuY718MzMkPHR/nvuOsRcD5/DzzE7nF8BM5xfATOcXwEznF8BM5xfATOcXwEzkV7POLSAeAxwHMA1ACsElVHxGRjQDuAnCs/K3rVfX5eg207uq4bv/u4x1mveOiE2a9v9hs1q0586H59FOyQ1XfdyV1a9+AoZL98mvLxmvGW4+t2Zj/3inu81ArlVzkUwBwn6ruEZGpAHaLyIvl2sOq+q/1Gx4R1Usw/Kp6FMDR8ud9IrIfwIJ6D4yI6uuc3vOLyCIAVwPYWb7pXhF5XUQ2i8jMiGPWiUiXiHTlYf+KSUTJqTj8IjIFwE8AfFNVewE8CmAJgOUY+c3gwfGOU9VNqtqpqp05tNRgyERUCxWFX0RyGAn+E6r6NACoareqFlW1BOAHAFbUb5hEVGvB8IuIAHgMwH5VfWjM7fPHfNttAPbVfnhEVC+V/LV/JYCvAtgrIq+Vb1sPYI2ILAegAA4CuLsuIzwPdEz9wK7n7FZfW8Ze2vtTkw5E1pphLzGdC2yDPT2wDXYc/WpP2W0NLM393OnLzPqC3MnIWtviXvPYoEygDVmq3/NWK5X8tf/nwLgTqyduT5+IeIUfkVcMP5FTDD+RUww/kVMMP5FTDD+RU1y6e1Qdt+jeuW+JWd/Vsti+g1P20t2ai7FddODHf/Z04BsCvXoYvXop2McG2vwI7C6O4enRd3BBV2DcIROgjx/CMz+RUww/kVMMP5FTDD+RUww/kVMMP5FTDD+RU6IJLkEsIscA/G7MTe0Ajic2gHPTqGNr1HEBHFu1ajm2hap6QSXfmGj4P/LgIl2q2pnaAAyNOrZGHRfAsVUrrbHx134ipxh+IqfSDv+mlB/f0qhja9RxARxbtVIZW6rv+YkoPWmf+YkoJamEX0RuFJE3ReRtEbk/jTFEEZGDIrJXRF4Tka6Ux7JZRHpEZN+Y22aJyIsi8lb547jbpKU0to0icrj83L0mIjenNLYOEflvEdkvIm+IyF+Xb0/1uTPGlcrzlviv/SKSBfAbANcDOATgVQBrVPVXiQ4kgogcBNCpqqn3hEXk8wBOA3hcVZeVb/s2gBOq+kD5B+dMVf27BhnbRgCn0965ubyhzPyxO0sDuBXA15Dic2eM63ak8LylceZfAeBtVT2gqsMAfgRgdQrjaHiqugPA2Tt6rAawpfz5Foy8eBIXMbaGoKpHVXVP+fM+AKM7S6f63BnjSkUa4V8A4N0xXx9CY235rQB+JiK7RWRd2oMZx9zytumj26fPSXk8Zwvu3Jyks3aWbpjnrpodr2stjfCPt35SI7UcVqrqNQBuAvCN8q+3VJmKdm5Oyjg7SzeEane8rrU0wn8IQMeYry8CcCSFcYxLVY+UP/YAeAaNt/tw9+gmqeWPPSmP50ONtHPzeDtLowGeu0ba8TqN8L8KYKmILBaRZgB3Ang2hXF8hIhMLv8hBiIyGcANaLzdh58FsLb8+VoA21Icyx9olJ2bo3aWRsrPXaPteJ3KRT7lVsZ3AGQBbFbVf058EOMQkYsxcrYHRlY2fjLNsYnIVgCrMDLrqxvABgD/AeDHAD4G4PcAvqKqif/hLWJsqzDyq+uHOzePvsdOeGx/DOBlAHuBD7cpXo+R99epPXfGuNYgheeNV/gROcUr/IicYviJnGL4iZxi+ImcYviJnGL4iZxi+ImcYviJnPp/Wge9Birza7YAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the Data\n",
    "\n",
    "**TASK 3: Normalize the X train and X test data by dividing by the max value of the image arrays.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test/255"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4: Reshape the X arrays to include a 4 dimension of the single channel. Similar to what we did for the numbers MNIST data set.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 28, 28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(10000, 28, 28,1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TASK 5: Convert the y_train and y_test values to be one-hot encoded for categorical analysis by Keras.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 0, 0, ..., 3, 0, 5], dtype=uint8)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_category_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_category_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_category_train"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Model\n",
    "\n",
    "**TASK 5: Use Keras to create a model consisting of at least the following layers (but feel free to experiment):**\n",
    "\n",
    "* 2D Convolutional Layer, filters=32 and kernel_size=(4,4)\n",
    "* Pooling Layer where pool_size = (2,2)\n",
    "\n",
    "* Flatten Layer\n",
    "* Dense Layer (128 Neurons, but feel free to play around with this value), RELU activation\n",
    "\n",
    "* Final Dense Layer of 10 Neurons with a softmax activation\n",
    "\n",
    "**Then compile the model with these parameters: loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Activation,Flatten,Conv2D,MaxPooling2D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(28,28,1),activation='relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 25, 25, 32)        544       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               589952    \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 591,786\n",
      "Trainable params: 591,786\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Model\n",
    "**TASK 6: Train/Fit the model to the x_train set. Amount of epochs is up to you.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 17s 288us/step - loss: 0.0704 - acc: 0.9726\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 16s 273us/step - loss: 0.0500 - acc: 0.9805\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 17s 291us/step - loss: 0.0437 - acc: 0.9831\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.0393 - acc: 0.9848\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 17s 275us/step - loss: 0.0358 - acc: 0.9864\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 17s 276us/step - loss: 0.0330 - acc: 0.9875\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 17s 278us/step - loss: 0.0306 - acc: 0.9886\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 16s 267us/step - loss: 0.0284 - acc: 0.9897\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 16s 274us/step - loss: 0.0268 - acc: 0.9902\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 16s 263us/step - loss: 0.0251 - acc: 0.9908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d81a54d748>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train,\n",
    "          y_category_train,\n",
    "          epochs=10,\n",
    "          )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the Model\n",
    "\n",
    "**TASK 7: Show the accuracy,precision,recall,f1-score the model achieved on the x_test data set. Keep in mind, there are quite a few ways to do this, but we recommend following the same procedure we showed in the MNIST lecture.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['loss', 'acc']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.metrics_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 77us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05364618001282215, 0.9813500144958496]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_category_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.83      0.85      1000\n",
      "          1       0.98      0.98      0.98      1000\n",
      "          2       0.80      0.91      0.85      1000\n",
      "          3       0.93      0.90      0.91      1000\n",
      "          4       0.87      0.82      0.84      1000\n",
      "          5       0.99      0.95      0.97      1000\n",
      "          6       0.74      0.74      0.74      1000\n",
      "          7       0.95      0.95      0.95      1000\n",
      "          8       0.99      0.97      0.98      1000\n",
      "          9       0.94      0.97      0.95      1000\n",
      "\n",
      "avg / total       0.91      0.90      0.90     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.85      0.85      1000\n",
      "          1       0.99      0.97      0.98      1000\n",
      "          2       0.88      0.83      0.85      1000\n",
      "          3       0.91      0.91      0.91      1000\n",
      "          4       0.83      0.88      0.85      1000\n",
      "          5       0.97      0.98      0.98      1000\n",
      "          6       0.73      0.76      0.74      1000\n",
      "          7       0.95      0.97      0.96      1000\n",
      "          8       0.99      0.97      0.98      1000\n",
      "          9       0.98      0.94      0.96      1000\n",
      "\n",
      "avg / total       0.91      0.91      0.91     10000\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great Job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
